{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b2d497",
   "metadata": {},
   "source": [
    "## 1. Setup & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb967599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU! Go to Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics YOLOv8\n",
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590fce1",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a9d07",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ CONFIG ============\n",
    "import os\n",
    "\n",
    "# Dataset paths (adjust to your Google Drive path)\n",
    "DATASET_ROOT = \"/content/drive/MyDrive/processed2\"\n",
    "\n",
    "# Training settings\n",
    "MODEL_SIZE = 'n'      # 'n'=nano, 's'=small, 'm'=medium, 'l'=large, 'x'=xlarge\n",
    "EPOCHS = 100          # YOLOv8 typically needs more epochs\n",
    "IMG_SIZE = 640        # Image size\n",
    "BATCH_SIZE = 16       # Adjust based on GPU memory\n",
    "PATIENCE = 20         # Early stopping patience\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = [\n",
    "    'Longitudinal_crack',   # D00\n",
    "    'Transverse_crack',     # D10  \n",
    "    'Alligator_crack',      # D20\n",
    "    'Other_damage',         # Other\n",
    "     'Pothole'              # D40\n",
    "]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"/content/yolov8_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Model: YOLOv8{MODEL_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch: {BATCH_SIZE}, ImgSize: {IMG_SIZE}\")\n",
    "print(f\"Classes: {NUM_CLASSES} - {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935d798",
   "metadata": {},
   "source": [
    "## 4. Create Dataset YAML\n",
    "YOLOv8 requires a YAML file describing the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f759f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset exists\n",
    "train_images = os.path.join(DATASET_ROOT, 'train', 'images')\n",
    "val_images = os.path.join(DATASET_ROOT, 'val', 'images')\n",
    "test_images = os.path.join(DATASET_ROOT, 'test', 'images')\n",
    "\n",
    "print(\"ðŸ“‚ Dataset structure:\")\n",
    "for split, path in [('Train', train_images), ('Val', val_images), ('Test', test_images)]:\n",
    "    if os.path.exists(path):\n",
    "        count = len([f for f in os.listdir(path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "        print(f\"  {split}: {count} images\")\n",
    "    else:\n",
    "        print(f\"  {split}: NOT FOUND at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b837c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset.yaml for YOLOv8\n",
    "import yaml\n",
    "\n",
    "dataset_yaml = {\n",
    "    'path': DATASET_ROOT,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'names': {i: name for i, name in enumerate(CLASS_NAMES)},\n",
    "    'nc': NUM_CLASSES\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(OUTPUT_DIR, 'dataset.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(f\"âœ“ Created {yaml_path}\")\n",
    "print(\"\\nContents:\")\n",
    "with open(yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63825c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ VERIFY & CLEAN DATASET ============\n",
    "# Remove images without labels and labels without images\n",
    "import os\n",
    "\n",
    "def clean_split(split_name, images_dir, labels_dir, dry_run=False):\n",
    "    \"\"\"Remove orphan images/labels in a split.\"\"\"\n",
    "    if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "        print(f\"  âš ï¸ {split_name}: directories not found, skipping\")\n",
    "        return 0, 0\n",
    "    \n",
    "    # Get file basenames (without extension)\n",
    "    images = {os.path.splitext(f)[0]: f for f in os.listdir(images_dir) \n",
    "              if f.lower().endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    labels = {os.path.splitext(f)[0]: f for f in os.listdir(labels_dir) \n",
    "              if f.lower().endswith('.txt')}\n",
    "    \n",
    "    # Find orphans\n",
    "    images_without_labels = set(images.keys()) - set(labels.keys())\n",
    "    labels_without_images = set(labels.keys()) - set(images.keys())\n",
    "    \n",
    "    removed_images = 0\n",
    "    removed_labels = 0\n",
    "    \n",
    "    # Remove orphan images\n",
    "    for basename in images_without_labels:\n",
    "        img_path = os.path.join(images_dir, images[basename])\n",
    "        if dry_run:\n",
    "            print(f\"    [DRY RUN] Would remove image: {images[basename]}\")\n",
    "        else:\n",
    "            os.remove(img_path)\n",
    "            print(f\"    ðŸ—‘ï¸ Removed image: {images[basename]}\")\n",
    "        removed_images += 1\n",
    "    \n",
    "    # Remove orphan labels\n",
    "    for basename in labels_without_images:\n",
    "        label_path = os.path.join(labels_dir, labels[basename])\n",
    "        if dry_run:\n",
    "            print(f\"    [DRY RUN] Would remove label: {labels[basename]}\")\n",
    "        else:\n",
    "            os.remove(label_path)\n",
    "            print(f\"    ðŸ—‘ï¸ Removed label: {labels[basename]}\")\n",
    "        removed_labels += 1\n",
    "    \n",
    "    valid_pairs = len(set(images.keys()) & set(labels.keys()))\n",
    "    print(f\"  {split_name}: {valid_pairs} valid pairs | removed {removed_images} images, {removed_labels} labels\")\n",
    "    return removed_images, removed_labels\n",
    "\n",
    "print(\"ðŸ” Checking dataset for orphan files...\\n\")\n",
    "\n",
    "# Set to False to actually delete files, True to just preview\n",
    "DRY_RUN = False  # âš ï¸ Set to False to actually remove files!\n",
    "\n",
    "total_img, total_label = 0, 0\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_dir = f\"{DATASET_ROOT}/{split}/images\"\n",
    "    label_dir = f\"{DATASET_ROOT}/{split}/labels\"\n",
    "    ri, rl = clean_split(split, img_dir, label_dir, dry_run=DRY_RUN)\n",
    "    total_img += ri\n",
    "    total_label += rl\n",
    "\n",
    "print(f\"\\n{'[DRY RUN] ' if DRY_RUN else ''}Total removed: {total_img} images, {total_label} labels\")\n",
    "if DRY_RUN:\n",
    "    print(\"âš ï¸ Set DRY_RUN = False and re-run to actually delete files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95888786",
   "metadata": {},
   "source": [
    "## 5. Check Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39994d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def analyze_labels(labels_dir, max_files=None):\n",
    "    \"\"\"Analyze label distribution.\"\"\"\n",
    "    if not os.path.exists(labels_dir):\n",
    "        print(f\"  âš ï¸ Not found: {labels_dir}\")\n",
    "        return\n",
    "    \n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]\n",
    "    if max_files:\n",
    "        label_files = label_files[:max_files]\n",
    "    \n",
    "    class_counts = Counter()\n",
    "    box_sizes = []\n",
    "    empty_count = 0\n",
    "    \n",
    "    for lf in label_files:\n",
    "        with open(os.path.join(labels_dir, lf), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if len(lines) == 0:\n",
    "            empty_count += 1\n",
    "            continue\n",
    "            \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                cls_id = int(parts[0])\n",
    "                w, h = float(parts[3]), float(parts[4])\n",
    "                class_counts[cls_id] += 1\n",
    "                box_sizes.append(w * h)\n",
    "    \n",
    "    print(f\"  Files: {len(label_files)} ({empty_count} empty)\")\n",
    "    print(f\"  Total boxes: {sum(class_counts.values())}\")\n",
    "    if box_sizes:\n",
    "        print(f\"  Avg box size: {np.mean(box_sizes)*100:.1f}% of image\")\n",
    "    print(f\"  Class distribution:\")\n",
    "    for cls_id in sorted(class_counts.keys()):\n",
    "        name = CLASS_NAMES[cls_id] if cls_id < len(CLASS_NAMES) else f'Unknown({cls_id})'\n",
    "        print(f\"    {cls_id}: {class_counts[cls_id]:5d} - {name}\")\n",
    "\n",
    "print(\"ðŸ“Š Train labels:\")\n",
    "analyze_labels(os.path.join(DATASET_ROOT, 'train', 'labels'))\n",
    "print(\"\\nðŸ“Š Val labels:\")\n",
    "analyze_labels(os.path.join(DATASET_ROOT, 'val', 'labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c8ce3",
   "metadata": {},
   "source": [
    "## 6. Train YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained YOLOv8 model\n",
    "model = YOLO(f'yolov8{MODEL_SIZE}.pt')\n",
    "\n",
    "print(f\"âœ“ Loaded YOLOv8{MODEL_SIZE} with pretrained COCO weights\")\n",
    "print(f\"  This provides a strong starting point for fine-tuning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6051d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    save=True,\n",
    "    device=0,  # Use GPU 0\n",
    "    workers=2,\n",
    "    project=OUTPUT_DIR,\n",
    "    name='train',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,  # Final LR = lr0 * lrf\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    box=7.5,       # Box loss gain\n",
    "    cls=0.5,       # Cls loss gain\n",
    "    dfl=1.5,       # DFL loss gain\n",
    "    hsv_h=0.015,   # HSV-Hue augmentation\n",
    "    hsv_s=0.7,     # HSV-Saturation augmentation\n",
    "    hsv_v=0.4,     # HSV-Value augmentation\n",
    "    degrees=10.0,  # Rotation augmentation\n",
    "    translate=0.1, # Translation augmentation\n",
    "    scale=0.5,     # Scale augmentation\n",
    "    fliplr=0.5,    # Horizontal flip\n",
    "    mosaic=1.0,    # Mosaic augmentation\n",
    "    mixup=0.1,     # Mixup augmentation\n",
    "    copy_paste=0.1,# Copy-paste augmentation\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup to Google Drive immediately after training\n",
    "import shutil\n",
    "\n",
    "# Define best model path\n",
    "best_model_path = os.path.join(OUTPUT_DIR, 'train', 'weights', 'best.pt')\n",
    "\n",
    "drive_backup = \"/content/drive/MyDrive/yolov8_backup\"\n",
    "os.makedirs(drive_backup, exist_ok=True)\n",
    "shutil.copy(best_model_path, drive_backup)\n",
    "print(f\"âœ“ Model backed up to {drive_backup}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a71259",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = os.path.join(OUTPUT_DIR, 'train', 'weights', 'best.pt')\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "# Evaluate\n",
    "metrics = best_model.val(data=yaml_path, imgsz=IMG_SIZE, batch=BATCH_SIZE)\n",
    "\n",
    "print(\"\\nðŸ“Š Validation Results:\")\n",
    "print(f\"  mAP@0.5:      {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision:    {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall:       {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a166c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class metrics\n",
    "print(\"\\nðŸ“Š Per-class AP@0.5:\")\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    if i < len(metrics.box.ap50):\n",
    "        print(f\"  {name}: {metrics.box.ap50[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4d75b",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Get validation images\n",
    "val_images_list = [f for f in os.listdir(val_images) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "sample_images = random.sample(val_images_list, min(6, len(val_images_list)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for ax, img_name in zip(axes.flat, sample_images):\n",
    "    img_path = os.path.join(val_images, img_name)\n",
    "    \n",
    "    # Run prediction\n",
    "    results = best_model.predict(img_path, conf=0.25, imgsz=IMG_SIZE, verbose=False)\n",
    "    \n",
    "    # Plot with boxes\n",
    "    result_img = results[0].plot()\n",
    "    ax.imshow(result_img[:, :, ::-1])  # BGR to RGB\n",
    "    \n",
    "    n_boxes = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "    ax.set_title(f'{img_name}\\n({n_boxes} detections)')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('YOLOv8 Road Damage Detection Results', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'predictions.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a487cefd",
   "metadata": {},
   "source": [
    "## 9. View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e04344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves from results.csv\n",
    "import pandas as pd\n",
    "\n",
    "results_csv = os.path.join(OUTPUT_DIR, 'train', 'results.csv')\n",
    "if os.path.exists(results_csv):\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()  # Remove whitespace from column names\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Box loss\n",
    "    axes[0, 0].plot(df['train/box_loss'], label='Train')\n",
    "    axes[0, 0].plot(df['val/box_loss'], label='Val')\n",
    "    axes[0, 0].set_title('Box Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Classification loss\n",
    "    axes[0, 1].plot(df['train/cls_loss'], label='Train')\n",
    "    axes[0, 1].plot(df['val/cls_loss'], label='Val')\n",
    "    axes[0, 1].set_title('Classification Loss')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # mAP\n",
    "    axes[1, 0].plot(df['metrics/mAP50(B)'], label='mAP@0.5')\n",
    "    axes[1, 0].plot(df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')\n",
    "    axes[1, 0].set_title('mAP')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Precision & Recall\n",
    "    axes[1, 1].plot(df['metrics/precision(B)'], label='Precision')\n",
    "    axes[1, 1].plot(df['metrics/recall(B)'], label='Recall')\n",
    "    axes[1, 1].set_title('Precision & Recall')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'training_curves.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print best metrics\n",
    "    print(f\"\\nðŸ† Best Results:\")\n",
    "    print(f\"  Best mAP@0.5:      {df['metrics/mAP50(B)'].max():.4f}\")\n",
    "    print(f\"  Best mAP@0.5:0.95: {df['metrics/mAP50-95(B)'].max():.4f}\")\n",
    "    print(f\"  Best Precision:    {df['metrics/precision(B)'].max():.4f}\")\n",
    "    print(f\"  Best Recall:       {df['metrics/recall(B)'].max():.4f}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Results file not found: {results_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e051c8",
   "metadata": {},
   "source": [
    "## 10. Test on Test Set (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test set\n",
    "test_results = best_model.predict(\n",
    "    source=test_images,\n",
    "    conf=0.25,\n",
    "    imgsz=IMG_SIZE,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    project=OUTPUT_DIR,\n",
    "    name='test_predictions',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Test predictions saved to {OUTPUT_DIR}/test_predictions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a2b44",
   "metadata": {},
   "source": [
    "## 11. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068dfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "print(\"ðŸ“¦ Exporting model...\")\n",
    "\n",
    "# Export to ONNX (for deployment)\n",
    "best_model.export(format='onnx', imgsz=IMG_SIZE)\n",
    "print(\"  âœ“ Exported to ONNX\")\n",
    "\n",
    "# Copy best weights to outputs\n",
    "import shutil\n",
    "final_model_path = os.path.join(OUTPUT_DIR, 'yolov8_road_damage_best.pt')\n",
    "shutil.copy(best_model_path, final_model_path)\n",
    "print(f\"  âœ“ Best weights saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a05726",
   "metadata": {},
   "source": [
    "## 12. Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download best model\n",
    "files.download(final_model_path)\n",
    "print(\"âœ“ Model downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b525a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook uses **Ultralytics YOLOv8** which provides:\n",
    "- âœ… Pretrained COCO weights for transfer learning\n",
    "- âœ… State-of-the-art detection architecture\n",
    "- âœ… Built-in augmentations (mosaic, mixup, copy-paste)\n",
    "- âœ… Automatic learning rate scheduling\n",
    "- âœ… Early stopping\n",
    "- âœ… Built-in metrics (mAP, precision, recall)\n",
    "- âœ… Easy export to ONNX/TensorRT for deployment\n",
    "\n",
    "**Expected mAP@0.5 for road damage:** 0.40-0.65 depending on dataset quality."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
