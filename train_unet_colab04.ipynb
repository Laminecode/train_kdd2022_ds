{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7b2d497",
      "metadata": {},
      "source": [
        "## 1. Setup & Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb967599",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU! Go to Runtime â†’ Change runtime type â†’ GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "install",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q segmentation-models-pytorch albumentations opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mount",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mount_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config",
      "metadata": {},
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ CONFIG ============\n",
        "import os\n",
        "\n",
        "# Dataset paths - MASKS ARE ALREADY CREATED IN segmentation2 folder\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/segmentation2\"\n",
        "\n",
        "# Training settings\n",
        "ENCODER = 'resnet34'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "EPOCHS = 100\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 0.0001\n",
        "PATIENCE = 20\n",
        "\n",
        "# Class names\n",
        "CLASS_NAMES = [\n",
        "    'background',\n",
        "    'Longitudinal_crack',\n",
        "    'Transverse_crack',\n",
        "    'Alligator_crack',\n",
        "    'Pothole',\n",
        "    'Other_damage'\n",
        "]\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"/content/unet_outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Model: U-Net with {ENCODER} encoder\")\n",
        "print(f\"Epochs: {EPOCHS}, Batch: {BATCH_SIZE}, ImgSize: {IMG_SIZE}\")\n",
        "print(f\"Classes: {NUM_CLASSES} - {CLASS_NAMES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "verify",
      "metadata": {},
      "source": [
        "## 4. Verify Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verify_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ“‚ Checking dataset structure...\\n\")\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    images_dir = os.path.join(DATASET_ROOT, split, 'images')\n",
        "    masks_dir = os.path.join(DATASET_ROOT, split, 'masks')\n",
        "    \n",
        "    if os.path.exists(images_dir) and os.path.exists(masks_dir):\n",
        "        n_images = len([f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        n_masks = len([f for f in os.listdir(masks_dir) if f.endswith('.png')])\n",
        "        print(f\"{split.upper()}:\")\n",
        "        print(f\"  Images: {n_images}\")\n",
        "        print(f\"  Masks:  {n_masks}\")\n",
        "        print()\n",
        "    else:\n",
        "        print(f\"âš ï¸ {split.upper()}: NOT FOUND\")\n",
        "        print()\n",
        "\n",
        "print(\"âœ“ Dataset verification complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dataset",
      "metadata": {},
      "source": [
        "## 5. Create Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dataset_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class RoadDamageDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform = transform\n",
        "        self.images = sorted([f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.images_dir, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        mask_name = os.path.splitext(img_name)[0] + '.png'\n",
        "        mask_path = os.path.join(self.masks_dir, mask_name)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "        \n",
        "        return image, mask.long()\n",
        "\n",
        "# Transforms\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset = RoadDamageDataset(\n",
        "    os.path.join(DATASET_ROOT, 'train', 'images'),\n",
        "    os.path.join(DATASET_ROOT, 'train', 'masks'),\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = RoadDamageDataset(\n",
        "    os.path.join(DATASET_ROOT, 'val', 'images'),\n",
        "    os.path.join(DATASET_ROOT, 'val', 'masks'),\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"âœ“ Train: {len(train_dataset)} | Val: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model",
      "metadata": {},
      "source": [
        "## 6. Build U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=3,\n",
        "    classes=NUM_CLASSES,\n",
        "    activation=None\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"âœ“ U-Net with {ENCODER} on {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "training_setup",
      "metadata": {},
      "source": [
        "## 7. Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "training_setup_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "        target_one_hot = torch.nn.functional.one_hot(target, NUM_CLASSES).permute(0, 3, 1, 2).float()\n",
        "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1 - dice.mean()\n",
        "\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "dice_loss = DiceLoss()\n",
        "\n",
        "def combined_loss(pred, target):\n",
        "    return ce_loss(pred, target) + dice_loss(pred, target)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "print(\"âœ“ Loss, optimizer, scheduler ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "metrics",
      "metadata": {},
      "source": [
        "## 8. Metrics Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metrics_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_iou(pred, target, num_classes):\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    ious = []\n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred == cls)\n",
        "        target_cls = (target == cls)\n",
        "        intersection = (pred_cls & target_cls).sum().float()\n",
        "        union = (pred_cls | target_cls).sum().float()\n",
        "        if union > 0:\n",
        "            ious.append((intersection / union).item())\n",
        "    return np.mean(ious) if ious else 0.0\n",
        "\n",
        "def calculate_pixel_accuracy(pred, target):\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    correct = (pred == target).sum()\n",
        "    total = target.numel()\n",
        "    return (correct / total).item()\n",
        "\n",
        "print(\"âœ“ Metrics ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "train_loop",
      "metadata": {},
      "source": [
        "## 9. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train_loop_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_iou': [], 'val_accuracy': [], 'lr': []}\n",
        "best_iou = 0.0\n",
        "patience_counter = 0\n",
        "best_model_path = os.path.join(OUTPUT_DIR, 'best_unet_model.pth')\n",
        "\n",
        "print(\"ðŸš€ Starting training...\\n\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    \n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, masks in tqdm(train_loader, desc='Training'):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = combined_loss(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = val_iou = val_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(val_loader, desc='Validation'):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss += combined_loss(outputs, masks).item()\n",
        "            val_iou += calculate_iou(outputs, masks, NUM_CLASSES)\n",
        "            val_accuracy += calculate_pixel_accuracy(outputs, masks)\n",
        "    \n",
        "    val_loss /= len(val_loader)\n",
        "    val_iou /= len(val_loader)\n",
        "    val_accuracy /= len(val_loader)\n",
        "    \n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_iou'].append(val_iou)\n",
        "    history['val_accuracy'].append(val_accuracy)\n",
        "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "    \n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | mIoU: {val_iou:.4f} | Acc: {val_accuracy:.4f}\")\n",
        "    \n",
        "    scheduler.step(val_iou)\n",
        "    \n",
        "    if val_iou > best_iou:\n",
        "        best_iou = val_iou\n",
        "        patience_counter = 0\n",
        "        torch.save({'model': model.state_dict(), 'iou': best_iou, 'history': history}, best_model_path)\n",
        "        print(f\"âœ… Best model saved! mIoU: {best_iou:.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "print(f\"\\nðŸŽ‰ Training done in {(time.time()-start_time)/60:.1f} min | Best mIoU: {best_iou:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "backup",
      "metadata": {},
      "source": [
        "## 10. Backup to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "backup_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "drive_backup = \"/content/drive/MyDrive/unet_models\"\n",
        "os.makedirs(drive_backup, exist_ok=True)\n",
        "shutil.copy(best_model_path, os.path.join(drive_backup, 'unet_best.pth'))\n",
        "print(\"âœ“ Backed up to Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "plots",
      "metadata": {},
      "source": [
        "## 11. Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plots_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "axes[0,0].plot(history['train_loss'], label='Train')\n",
        "axes[0,0].plot(history['val_loss'], label='Val')\n",
        "axes[0,0].set_title('Loss')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0,1].plot(history['val_iou'])\n",
        "axes[0,1].axhline(best_iou, color='r', linestyle='--', label=f'Best: {best_iou:.4f}')\n",
        "axes[0,1].set_title('mIoU')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1,0].plot(history['val_accuracy'])\n",
        "axes[1,0].set_title('Accuracy')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1,1].plot(history['lr'])\n",
        "axes[1,1].set_title('Learning Rate')\n",
        "axes[1,1].set_yscale('log')\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'training_curves.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "test",
      "metadata": {},
      "source": [
        "## 12. Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "test_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load(best_model_path)\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "model.eval()\n",
        "\n",
        "test_dataset = RoadDamageDataset(\n",
        "    os.path.join(DATASET_ROOT, 'test', 'images'),\n",
        "    os.path.join(DATASET_ROOT, 'test', 'masks'),\n",
        "    transform=val_transform\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "test_iou = test_acc = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, masks in tqdm(test_loader, desc='Testing'):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        outputs = model(images)\n",
        "        test_iou += calculate_iou(outputs, masks, NUM_CLASSES)\n",
        "        test_acc += calculate_pixel_accuracy(outputs, masks)\n",
        "\n",
        "test_iou /= len(test_loader)\n",
        "test_acc /= len(test_loader)\n",
        "\n",
        "print(f\"\\nðŸ“Š Test Results: mIoU={test_iou:.4f} | Accuracy={test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "viz",
      "metadata": {},
      "source": [
        "## 13. Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viz_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "COLORS = np.array([[0,0,0], [255,0,0], [0,255,0], [0,0,255], [255,255,0], [255,0,255]], dtype=np.uint8)\n",
        "\n",
        "test_imgs = os.listdir(os.path.join(DATASET_ROOT, 'test', 'images'))\n",
        "samples = random.sample(test_imgs, min(6, len(test_imgs)))\n",
        "\n",
        "fig, axes = plt.subplots(6, 3, figsize=(15, 24))\n",
        "\n",
        "for idx, img_name in enumerate(samples):\n",
        "    img_path = os.path.join(DATASET_ROOT, 'test', 'images', img_name)\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    mask_path = os.path.join(DATASET_ROOT, 'test', 'masks', os.path.splitext(img_name)[0] + '.png')\n",
        "    gt_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    aug = val_transform(image=image)\n",
        "    inp = aug['image'].unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pred = torch.argmax(model(inp), dim=1).cpu().numpy()[0]\n",
        "    \n",
        "    img_r = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    gt_r = cv2.resize(gt_mask, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "    \n",
        "    axes[idx,0].imshow(img_r)\n",
        "    axes[idx,0].set_title(f'Original\\n{img_name}')\n",
        "    axes[idx,0].axis('off')\n",
        "    \n",
        "    axes[idx,1].imshow(COLORS[gt_r])\n",
        "    axes[idx,1].set_title('Ground Truth')\n",
        "    axes[idx,1].axis('off')\n",
        "    \n",
        "    axes[idx,2].imshow(COLORS[pred])\n",
        "    axes[idx,2].set_title('Prediction')\n",
        "    axes[idx,2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'predictions.png'), dpi=150)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}